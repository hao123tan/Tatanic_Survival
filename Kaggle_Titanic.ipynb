{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import copy\n",
    "from tensorflow import keras\n",
    "# it's a library that we work with plotly\n",
    "import plotly.offline as py \n",
    "py.init_notebook_mode(connected=True) # this code, allow us to work with offline plotly version\n",
    "import plotly.graph_objs as go # it's like \"plt\" of matplot\n",
    "import plotly.tools as tls # It's useful to we get some tools of plotly\n",
    "import warnings # This library will be used to ignore some warnings\n",
    "from collections import Counter # To do counter of some features\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. data preprocessing\n",
    "train_df = pd.read_csv(\"./kaggle_train.csv\", index_col=0)\n",
    "test_df = pd.read_csv(\"./kaggle_test.csv\")\n",
    "# The name of passenger and Ticket are useless when we want to use data to train my model\n",
    "train_df.pop(\"Name\")\n",
    "test_df.pop(\"Name\")\n",
    "train_df.pop(\"Ticket\")\n",
    "test_df.pop(\"Ticket\")\n",
    "train_df[\"Cabin\"] = train_df[\"Cabin\"].fillna(\"Unknown\")\n",
    "test_df[\"Cabin\"] = test_df[\"Cabin\"].fillna(\"Unknown\")\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"Unknown\")\n",
    "test_df[\"Embarked\"] = test_df[\"Embarked\"].fillna(\"Unknown\")\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(28)\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(28)\n",
    "train_df[\"alone\"] = train_df[\"SibSp\"].apply(lambda x : \"Y\" if x > 0 else \"N\")\n",
    "test_df[\"alone\"] = test_df[\"SibSp\"].apply(lambda x : \"Y\" if x > 0 else \"N\")\n",
    "train_df[\"Cabin\"] = train_df[\"Cabin\"].apply(lambda x : \"Unknown\" if x == \"Unknown\" else re.findall(\"^\\w\", x)[0])\n",
    "test_df[\"Cabin\"] = test_df[\"Cabin\"].apply(lambda x : \"Unknown\" if x == \"Unknown\" else re.findall(\"^\\w\", x)[0])\n",
    "# train_df.drop(train_df[np.isnan(train_df[\"Age\"])].index, inplace=True)\n",
    "new_train_df = copy.deepcopy(train_df)\n",
    "y_train = train_df.pop('Survived')\n",
    "# y_eval = test_df.pop('Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Data format </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    train_df, y_train, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\"Sex\", \"SibSp\", \"Parch\", \"Pclass\", \"Cabin\", \"Embarked\", \"alone\"]\n",
    "numeric_columns = [\"Age\", \"Fare\"]\n",
    "feature_columns = []\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        categorical_column, vocab)))\n",
    "\n",
    "for categorical_column in numeric_columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(categorical_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs = 10, \n",
    "                 shuffle = True, batch_size = 32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> <font color=\"black\" align=\"center\">Estimator Mehod</font> </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_out_dir = \"./Titanic_linear_model\"\n",
    "if not os.path.exists(linear_out_dir):\n",
    "    os.mkdir(linear_out_dir)\n",
    "linear_estimator = tf.compat.v1.estimator.LinearClassifier(\n",
    "    model_dir = linear_out_dir,\n",
    "    n_classes=2,\n",
    "    feature_columns=feature_columns)\n",
    "linear_estimator.train(input_fn = lambda : make_dataset(x_train_all, y_train_all, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = linear_estimator.evaluate(input_fn = lambda : make_dataset(x_test, y_test, epochs=1, shuffle = False))\n",
    "accuracy_list.append(history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_out_dir = \"./Tatanic_dnn_model\"\n",
    "if not os.path.exists(dnn_out_dir):\n",
    "    os.mkdir(dnn_out_dir)\n",
    "dnn_estimator = tf.compat.v1.estimator.DNNClassifier(\n",
    "    model_dir=dnn_out_dir,\n",
    "    n_classes=2,\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[100, 100],\n",
    "    activation_fn=tf.nn.relu,\n",
    "    optimizer=\"Adam\")\n",
    "dnn_estimator.train(input_fn = lambda : make_dataset(\n",
    "                    x_train_all, y_train_all, epochs=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = dnn_estimator.evaluate(input_fn= lambda : make_dataset(\n",
    "                       x_test, y_test, epochs=1, shuffle = False))\n",
    "accuracy_list.append(history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Model Method </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\"),])\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer = keras.optimizers.SGD(lr=0.01), \n",
    "                  metrics = [\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(x_train, y_train, epochs=100)\n",
    "valid_dataset = make_dataset(x_valid, y_valid, epochs=100)\n",
    "logdir = './Tatanic_model'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_model_file = os.path.join(logdir, \"train_model.h5\")\n",
    "model.fit(train_dataset, validation_data=valid_dataset, \n",
    "                    steps_per_epoch=15, validation_steps=8, \n",
    "                    epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.evaluate(make_dataset(x_test, y_test, epochs=1, shuffle = False))\n",
    "accuracy_list.append(history[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Bar(\n",
    "            x = np.array(['Linear'], dtype=object),\n",
    "            y = np.array([accuracy_list[0]], dtype=object),\n",
    "            name='LinearEstimator'\n",
    "    )\n",
    "\n",
    "trace1 = go.Bar(\n",
    "            x = np.array(['DNN'], dtype=object),\n",
    "            y = np.array([accuracy_list[1]], dtype=object),\n",
    "            name='DNNEstimator'\n",
    "    )\n",
    "\n",
    "trace2 = go.Bar(\n",
    "            x = np.array(['Model'], dtype=object),\n",
    "            y = np.array([accuracy_list[2]], dtype=object),\n",
    "            name='Model'\n",
    "    )\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='accuracy'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Various models'\n",
    "    ),\n",
    "    title='Accuracy Comparison Among Various Models'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For that, we would use LinearEstimator as main model to help us to predict Tatanic Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "features = ['Age', 'Cabin', 'Embarked', 'Fare', 'Parch', 'Pclass', 'Sex', 'SibSp', 'alone']\n",
    "for feature in features:\n",
    "    feature_list.append(test_df[feature])\n",
    "predictor = model.predict(feature_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    survived = []\n",
    "    for i in data:\n",
    "        if (i[0] > i[1]):\n",
    "            survived.append(0)\n",
    "        else:\n",
    "            survived.append(1)\n",
    "    return survived\n",
    "test_df[\"Survived\"] = get_data(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace0 = go.Bar(\n",
    "            x = np.array(['Dead'], dtype=object),\n",
    "            y = np.array([test_df[\"Survived\"].value_counts()[0]], dtype=object),\n",
    "            name='Dead'\n",
    "    )\n",
    "\n",
    "trace1 = go.Bar(\n",
    "            x = np.array(['Survive'], dtype=object),\n",
    "            y = np.array([test_df[\"Survived\"].value_counts()[1]], dtype=object),\n",
    "            name='Survive'\n",
    "    )\n",
    "\n",
    "data = [trace0, trace1]\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict(\n",
    "        title='Number'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Various situation'\n",
    "    ),\n",
    "    title='Prediction for Tiatanic Survival'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='grouped-bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> this is Survived predict used to submit in Kaggle</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionObj = test_df[[\"PassengerId\", \"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubmissionObj.to_csv(\"Submission_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
